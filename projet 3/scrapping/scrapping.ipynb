{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T11:59:44.101671Z",
     "start_time": "2020-05-19T11:59:43.190993Z"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml.html\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ROLE DES IMPORTATIONS\n",
    "BeautifulSoup: RECUPERER LES INFORMATIONS DANS UNE PAGE\n",
    "webdriver: AGIR SUR LA PAGE (click, entre du texte, ...)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T11:59:44.107625Z",
     "start_time": "2020-05-19T11:59:44.103642Z"
    }
   },
   "outputs": [],
   "source": [
    "lien = \"https://www.indeed.fr/\"\n",
    "metier=[\"developpeur\", \"data scientist\", \"data analyst\", \"business intelligence\"]\n",
    "contrat = [\"CDI\", \"CDD\", \"freelance\"]\n",
    "lieux = [\"Paris\", \"Lyon\", \"Toulouse\", \"Nantes\", \"Bordeaux\"]\n",
    "scrap = [\"titre\", \"nom_boite\", \"adresse_boite\", \"poste_boite\",\"publication_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T11:59:57.054719Z",
     "start_time": "2020-05-19T11:59:44.109622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Looking for [chromedriver 81.0.4044.138 win32] driver in cache \n",
      "[WDM] - File found in cache by path [C:\\Users\\Utilisateur\\.wdm\\drivers\\chromedriver\\81.0.4044.138\\win32\\chromedriver.exe]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "[]\n",
      "\n",
      "[]\n",
      "\n",
      "[]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>entreprise</th>\n",
       "      <th>localisation</th>\n",
       "      <th>type emploi</th>\n",
       "      <th>description poste</th>\n",
       "      <th>salaire</th>\n",
       "      <th>nb jours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CDI - Data scientist senior H/F</td>\n",
       "      <td>BIOMERIEUX sa</td>\n",
       "      <td>Craponne (69)</td>\n",
       "      <td></td>\n",
       "      <td>Acteur mondial dans le domaine du diagnostic i...</td>\n",
       "      <td></td>\n",
       "      <td>il y a 19 jours\\n- Continuer pour postuler\\nSi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst-Scientist F/H</td>\n",
       "      <td>BIRDZ</td>\n",
       "      <td>Lyon 7e (69)</td>\n",
       "      <td></td>\n",
       "      <td>Intitulé du Poste : Data Analyst-Data Scientis...</td>\n",
       "      <td></td>\n",
       "      <td>Apec.fr - il y a 19 jours\\n- Continuer pour po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst-Data Scientist H/F</td>\n",
       "      <td>BIRDZ</td>\n",
       "      <td>Lyon 7e (69)</td>\n",
       "      <td></td>\n",
       "      <td>1. NOTRE IDENTITE\\nChez Birdz, nous avons la c...</td>\n",
       "      <td></td>\n",
       "      <td>Il y a plus de 30 jours\\nSignaler un abus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data scientist – Machine learning</td>\n",
       "      <td>Davidson consulting</td>\n",
       "      <td>Lyon (69)</td>\n",
       "      <td></td>\n",
       "      <td>Pour le compte d’un de nos clients grands comp...</td>\n",
       "      <td></td>\n",
       "      <td>DAVIDSON - Il y a plus de 30 jours\\n- Continue...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               titre           entreprise   localisation  \\\n",
       "0    CDI - Data scientist senior H/F        BIOMERIEUX sa  Craponne (69)   \n",
       "1         Data Analyst-Scientist F/H                BIRDZ   Lyon 7e (69)   \n",
       "2    Data Analyst-Data Scientist H/F                BIRDZ   Lyon 7e (69)   \n",
       "3  Data scientist – Machine learning  Davidson consulting      Lyon (69)   \n",
       "\n",
       "  type emploi                                  description poste salaire  \\\n",
       "0              Acteur mondial dans le domaine du diagnostic i...           \n",
       "1              Intitulé du Poste : Data Analyst-Data Scientis...           \n",
       "2              1. NOTRE IDENTITE\\nChez Birdz, nous avons la c...           \n",
       "3              Pour le compte d’un de nos clients grands comp...           \n",
       "\n",
       "                                            nb jours  \n",
       "0  il y a 19 jours\\n- Continuer pour postuler\\nSi...  \n",
       "1  Apec.fr - il y a 19 jours\\n- Continuer pour po...  \n",
       "2          Il y a plus de 30 jours\\nSignaler un abus  \n",
       "3  DAVIDSON - Il y a plus de 30 jours\\n- Continue...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metier_recherche = [\"data scientist\"]\n",
    "contrat_recherche = [\"CDI\"]\n",
    "lieu_recherche = [\"Lyon\"]\n",
    "\n",
    "# ouverture de la page et du lien\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(lien)\n",
    "driver.maximize_window()\n",
    "# insertion des métiers recherchés\n",
    "for i in metier_recherche:\n",
    "    time.sleep(0.2)\n",
    "    driver.find_element_by_id(\"text-input-what\").send_keys(i, \", \")\n",
    "# insertion des lieux recherchés\n",
    "for i in lieu_recherche:\n",
    "    time.sleep(0.2)\n",
    "    driver.find_element_by_id(\"text-input-where\").send_keys(i, \", \")    \n",
    "driver.find_element_by_class_name(\"icl-WhatWhere-button\").click()\n",
    "\n",
    "nb_lign = []\n",
    "# obtenir les données voulues et se déplacer de page en page\n",
    "first_page = True\n",
    "while True:   \n",
    "    time.sleep(1)\n",
    "    # fermeture de la fenetre supérieure si elle apparait\n",
    "    try:\n",
    "        driver.find_element_by_class_name(\"popover-close-link\").click()\n",
    "    except:\n",
    "        None\n",
    "    # obtention des propositions faites par la page\n",
    "    propositions = [i for i in driver.find_elements_by_class_name('jobsearch-SerpJobCard')]\n",
    "    columns = [\"titre\", \"entreprise\", \"localisation\", \"type emploi\", \"description poste\", \"salaire\", \"nb jours\"]\n",
    "    df = pd.DataFrame(columns = columns) \n",
    "    for i in propositions[:4]:\n",
    "        i.click()\n",
    "        time.sleep(0.2)\n",
    "        description = driver.find_elements_by_class_name(\"jobMetadataHeader-itemWithIcon-label\")\n",
    "        L = [description[0].text,'','']\n",
    "        # test\n",
    "        page = requests.get(driver.current_url)\n",
    "        bs = BeautifulSoup(page.content, features='lxml')\n",
    "        print(bs.find_all('span',attrs={\"class\":\"copany\"}))\n",
    "        print('')\n",
    "        #print(bs.find_all('span',attrs={\"class\":\"jobMetadataHeader-itemWithIcon-label\"}))\n",
    "            #for p in i.find_all('span',attrs={\"class\":\"jobMetadataHeader-itemWithIcon-label\"}):\n",
    "            #print(i.text)\n",
    "        \n",
    "    #    for i in description:\n",
    "     #       print(i.text)\n",
    "     #   print(len(description))\n",
    "     #   print(\" \\n\")\n",
    "        try:\n",
    "            c = [\n",
    "                driver.find_element_by_id(\"vjs-jobtitle\").text,   # id: vjs-jobtitle   titre job\n",
    "                driver.find_element_by_id(\"vjs-cn\").text,   # id: vjs-cn  entreprise\n",
    "                L[0],  # id: vjs-loc  localisation class: jobMetadataHeader-itemWithIcon-label)\n",
    "                L[1], # type emploi (CDI) (class: jobMetadataHeader-itemWithIcon-label)  jobSectionHeader\n",
    "                driver.find_element_by_id(\"vjs-desc\").text, # id: vjs-desc    description poste\n",
    "                L[2], # salaire\n",
    "                driver.find_element_by_id(\"vjs-footer\").text, # id: info-footer   il y a .. jours\n",
    "                ]   \n",
    "            df_line = pd.DataFrame([c], columns=columns)\n",
    "            df = pd.concat([df,df_line], ignore_index=True)  \n",
    "        except:\n",
    "            print('', end='')\n",
    "    break\n",
    "    # passer sur la page suivante (si elle existe) sinon, sortir\n",
    "    change = [i for i in driver.find_elements_by_class_name('np')]\n",
    "    if first_page or len(change)==2:\n",
    "        [i for i in driver.find_elements_by_class_name('np')][-1].click()\n",
    "    else: \n",
    "        break\n",
    "    first_page = False\n",
    "df.head()\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:42:07.382444Z",
     "start_time": "2020-05-19T09:41:55.482Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T16:05:44.412742Z",
     "start_time": "2020-05-18T16:05:44.391739Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
